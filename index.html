<!doctype html>
<html>
	<head>
		<meta charset="utf-8">

		<title>Discontinuous Regression Surface Fitting</title>

		<meta name="description" content="Discontinuous Regression Surface Fitting">
		<meta name="author" content="Riddhiman Saha">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/blood.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
		<!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css"> -->
		<link href="css/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
		<link href="css/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section id="title">
					<img data-src="media/movieblack.gif">
					<h3 style="color: #f82249;">Discontinuous Regression Surface Fitting</h3>
					<p>Group Project</p>
					<p><strong>Statistics Comprehensive</strong></p>
				</section>
				<section id="introduction"  style="text-align: left; font-size: 40px;">
					<section>
						<h3>Introduction</h3>
						<ul>
							<li class="fragment fade-up">
								What are we going to do?
							</li>
							<li style="list-style-type: none;" class="fragment fade-in">
								We have a collection of points in $\mathbb{R}^2$ arranged in a grid inside $[0,1)\times[0,1)$, and also the associated $z$ values for each point. We want to perform &ldquo;smoothing&rdquo; for the given data, and predict $z$ value for some point $(x_0,y_0)\in[0,1)\times[0,1)$.<br>Note that, the underlying function 'may have jumps at some locations, but mostly smooth'.
								<!-- So we can think of the following:<br>
								$$z_{ij}=f(x_i, y_j)+\epsilon_{ij}; i,j=1,\ldots,n;$$where $x_i=y_i=\frac{i-1}{n}, i=1,\ldots,n$ & $\epsilon_{ij}$ random error<br>
								Given $(x_0,y_0) \in [0,1)\times[0,1)$, we want to predict $f(x_0, y_0)$ -->
							</li>
							<li class="fragment fade-up">
								Why are we interested?
							</li>
							<li style="list-style-type: none;" class="fragment fade-in">
								Not just another new type of regression. It has got many practical applications. For example: (contd.)
							</li>
						</ul>
					</section>
					<section>
						<ul>
							<li>
								Image Denoising:
								<br>
								<div style="text-align: center;">
									<div style="display: inline; vertical-align: middle;">
										<img data-src="media/noise.jpeg" width="20%">
									</div>
									<div style="display: inline;">
										$\Longrightarrow$
									</div>
									<div style="display: inline; vertical-align: middle;">
										<img data-src="media/original.jpeg" width="20%">
									</div>
								</div>
							</li>
							<li class="fragment" data-fragment-index="1">
								<span class="fragment" data-fragment-index="1">Working with Elevation data </span><span class="fragment" data-fragment-index="2"> or Temparature Data:</span>
								<br>
								<div style="text-align: center;">
									<img data-src="media/elevation.png" style="height: 30vh; border-right: 3px solid white; padding-right: 15px" class="fragment" data-fragment-index="1">
									<img data-src="media/temparature.jpg" style="height: 30vh; padding-left: 10px" class="fragment" data-fragment-index="2">
								</div>
							</li>
						</ul>
					</section>
					<section>
						<h3>
							We are going to discuss:
						</h3>
						<ol>
							<li>Defining the problem</li>
							<li>Describing the conventional method</li>
							<li>Description of the proposed method considering jumps</li>
							<li>Results from simulation study</li>
							<li>Concluding remarks</li>
						</ol>
					</section>
				</section>
				<section style="text-align: left;">
					<section>
						<h3>
							Problem Statement
						</h3>
						$$f:[0,1)\times[0,1)\rightarrow\mathbb{R}^2$$
						We are given data-points in an $n\times n$ grid: $\{(x_i,y_j)|i,j=1,\ldots,n\}$, where $x_i=y_i=\frac{i-1}{n}$
						$$z_{ij}=f(x_i,y_j)+\epsilon_{ij}; \epsilon_{ij}\text{ i.i.d. error}$$
						Given $(x_0,y_0)\in[0,1)\times[0,1)$, want to predict $f(x_0,y_0)$
					</section>
				</section>
				<section style="text-align: left; font-size: 34px;">
					<section>
						<h4>Conventional Method : Kernel Smoothing (2-D)</h4>
						<div class="r-stack">
							<div class="fragment fade-out" data-fragment-index="0">
								We can do nonparametric regression, with bivariate kernel.
								<ul>
									<li>
										Any <strong>bivariate density</strong> function can be used.
									</li>
									<li>
										Given any univariate kernel $f(x)$, we can define $K(x,y)=f(x)f(y)$
									</li>
									<li>
										For example, univariate <strong>triangular</strong> kernel is given by, $(1-|x|)I_{\{|x|\leq 1\}}$. So we can define, $K(x,y)=(1-|x|)(1-|y|)I_{\{|x|\leq 1, |y|\leq 1\}}$
									</li>
								</ul>
							</div>
							<div class="fragment current-visible" data-fragment-index="0" style="text-align: center;">
								<p>Plot of Triangular Kernel</p>
								<iframe data-src="media/triangular.html" scrolling="no" height="500px" width="550px" frameborder="0" style="display: block; margin: 0 auto;"></iframe>
							</div>
							<div class="fragment current-visible" data-fragment-index="1" style="font-size: 30px;">
								To predict the response variable at $(x_0, y_0)$, we can use <strong>Local polynomial smoothing</strong>.
								For local polynomial of $0$-degree, we minimize,
								$$\sum_{i=1}^n\sum_{j=1}^n(z_{ij}-\alpha)^2 K\left(\frac{x_i-x_0}{h},\frac{y_j-y_0}{h}\right)$$
								where, $h$ is the <strong>smoothing bandwidth</strong>.
								<br>
								The estimated value at $(x_0,y_0)$ is given by, 
								$$\hat{f_0}(x_0, y_0)=\hat{\alpha}=\frac{\sum_{i=1}^n\sum_{j=1}^n w_{ij}z_{ij}}{\sum_{i=1}^n\sum_{j=1}^n w_{ij}}$$
								where, $w_{ij}=K\left(\frac{x_i-x_0}{h}, \frac{y_j-y_0}{h}\right)$
							</div>
							<div class="fragment current-visible" data-fragment-index="2" style="font-size: 26px;">
								For local polynomial of $1$-degree, we minimize,
								$$\sum_{i=1}^n\sum_{j=1}^n(z_{ij}-\alpha-\beta_1(x_i-x_0)-\beta_2(y_j-y_0))^2 K\left(\frac{x_i-x_0}{h},\frac{y_j-y_0}{h}\right)$$
								<br>
								The estimated value at $(x_0,y_0)$ is given by,
								<div style="font-size: 20px;"> 
									$$\hat{f_1}(x_0, y_0)=\hat{\alpha}\text{, where}, [\hat{\alpha}, \hat{\beta_1}, \hat{\beta_2}]^T=\\
									\begin{bmatrix}
									\sum\sum w_{ij} & \sum\sum w_{ij}(x_i-x_0) & \sum\sum w_{ij}(y_j-y_0)\\
									\sum\sum w_{ij}(x_i-x_0) & \sum\sum w_{ij}(x_i-x_0)^2 & \sum\sum w_{ij}(x_i-x_0)(y_j-y_0)\\
									\sum\sum w_{ij}(y_j-y_0) & \sum\sum w_{ij}(x_i-x_0)(y_j-y_0) & \sum\sum w_{ij}(y_j-y_0)^2
									\end{bmatrix}^{-1}
									\begin{bmatrix}
									\sum\sum z_{ij}w_{ij}\\
									\sum\sum z_{ij}w_{ij}(x_i-x_0)\\
									\sum\sum z_{ij}w_{ij}(y_j-y_0)
									\end{bmatrix}$$
								</div>
							</div>
						</div>
					</section>
					<section style="font-size: 26px;">
						<h4>
							Example of Kernel Smoothing
						</h4>
						<div class="r-stack">
							<div class="fragment fade-out" data-fragment-index="0">
								Consider the function, $f:[0,1)\times[0,1)\rightarrow \mathbb{R}$
								$$f(x, y)=-2(x-0.5)^2 - 2(y-0.5)^2 + I_{\{(x-0.5)^2 + (y-0.5)^2 \leq 0.25^2\}}$$
								$f$ was evaluated on a $100\times 100$ grid. Here is the plot of the points and the true surface:
								<br>
								<div style="text-align: center;">
									<iframe src="media/truevalues.html" scrolling="no" height="450px" width="850px" frameborder="0"></iframe>
								</div>
							</div>
							<div class="fragment current-visible" data-fragment-index="0">
								Consider the function, $f:[0,1)\times[0,1)\rightarrow \mathbb{R}$
								$$f(x, y)=-2(x-0.5)^2 - 2(y-0.5)^2 + I_{\{(x-0.5)^2 + (y-0.5)^2 \leq 0.25^2\}}$$
								$f$ was evaluated on a $100\times 100$ grid, and noises were added from $N(0, \sigma^2)$ with $\sigma=0.3$. Here is the noisy input data:
								<br>
								<div style="text-align: center;">
									<iframe data-src="media/input.html" scrolling="no" height="450px" width="850px" frameborder="0"></iframe>
								</div>
							</div>
							<div class="fragment current-visible" data-fragment-index="1">
								On the noisy input, we performed the conventional kernel smoothing with triangular density and <strong>$h=0.15$</strong>
								<br>
								Here is the fitted surface for degree-$0$:
								<div style="text-align: center;">
									<iframe data-src="media/conv_deg0.html" scrolling="no" height="450px" width="850px" frameborder="0"></iframe>
								</div>
							</div>
							<div class="fragment current-visible" data-fragment-index="2">
								On the noisy input, we performed the conventional kernel smoothing with triangular density and <strong>$h=0.15$</strong>
								<br>
								Here is the fitted surface for degree-$1$:
								<div style="text-align: center;">
									<iframe data-src="media/conv_deg1.html" scrolling="no" height="450px" width="850px" frameborder="0"></iframe>
								</div>
							</div>
						</div>
					</section>
					<section>
						<h4>
							Drawbacks : Conventional Kernel Smoothing
						</h4>
						<div>
							The jump imformation was completely lost in the last two outputs. The fitted surface was smooth near the &ldquo;Jump Location Curve&rdquo;, but in reality, there is a jump with magnitude $1$ in the true surface.
						</div>
						<div class="fragment fade-down">
							$$\Bigg\downarrow$$
							To overcome the issue, we propose a method where we try to preserve the jump information while doing kernel smoothing.
						</div>
					</section>
				</section>
				<section  style="text-align: left;">
					<section>
						<h4>
							Proposed Method
						</h4>
						<ul>
							<li>
								We want to preserve the jump information.
							</li>
							<li>
								To estimate $f$ at $(x_0,y_0)$, we shall <strong>not</strong> consider <strong>all</strong> points. Instead, we can do a neighbourhood-based clustering.
							</li>
							<li>
								For satisfactory performance, we introduce some more assumptions on $f$.
							</li>
						</ul>
					</section>
					<section>
						<h4>
							Modified Problem Statement
						</h4>
						<div style="font-size: 30px;">
							$$f:[0,1)\times[0,1)\rightarrow\mathbb{R}^2$$
							We are given data-points in an $n\times n$ grid: $\{(x_i,y_j)|i,j=1,\ldots,n\}$, where $x_i=y_i=\frac{i-1}{n}$
							$$z_{ij}=f(x_i,y_j)+\epsilon_{ij}; \epsilon_{ij}\sim N(0, \sigma^2)\text{ i.i.d., }\sigma^2\text{ unknown.}$$
							$f$ has the following properties:
							<ul>
								<li>
									Except at jump location curves, $f$ is continuous & locally linear(i.e., can be approximated by a plane.)
								</li>
								<li>
									The jump location curves are smooth, so that, it can be approximated by a straight line in a small region.
								</li>
							</ul>
							Under this setup, given $(x_0, y_0)\in[0, 1)\times[0,1)$, we want to predict $f(x_0, y_0)$.
						</div>
					</section>
				</section>
				<section style="text-align: left;">
					<section>
						<h4>
							Proposed Method : Step 1
						</h4>
						<div style="font-size: 30px;">
							Given $(x_0,y_0)$, first we fix a neighbourhood around this point.
							<br>
							Fix some $l$. Then we have the square neighbourhood, $$S=[x_0-l,x_0+l]\times[y_0-l,y_0+l]$$
							<br>
							Define, $N(x_0, y_0)=$ set of design points contained in $S$.
							<!-- <br>
							For points near boundary, the neighbourhood may not be a square. We can do &ldquo;padding&rdquo;, or can work with the truncated neighbourhood. -->
							<hr>
							For $100\times 100$ grid, if $(x_0,y_0)$ is a design point, then $l=0.05\Rightarrow N(x_0,y_0)$ is a set of $121$ points arranged in a $11\times 11$ grid.
							<br>
							We say that, this is a neighbourhood with &ldquo;window-width $11$&rdquo;.
						</div>
					</section>
					<section>
						<h4>
							Proposed Method : Step 1 (contd.)
						</h4>
						<div style="font-size: 30px;">
							<strong>Example:</strong>
							<!-- <br> -->
							Same function $f$, added noise with $\sigma=0.1$
							<br>
							Say, $(x_0,y_0)=(0.32, 0.70)$ and $l=0.06$
							<br>
							So, $N(x_0, y_0)=\{0.26, 0.28, \ldots,0.38\}\times\{0.64,0.66,\ldots,0.76\}$
							<br>
							How does it look like?
							<br>
							<div style="text-align: center;" class="r-stack">
								<div class="fragment current-visible">
									<iframe data-src="media/grid.html" scrolling="no" height="500px" width="500px" frameborder="0"></iframe>
								</div>
								<div class="fragment">
									<iframe data-src="media/zoomgrid.html" scrolling="no" height="500px" width="500px" frameborder="0"></iframe>
								</div>
							</div>
						</div>
					</section>
				</section>
				<section style="text-align: left;">
					<section>
						<h4>
							Proposed Method : Step 2
						</h4>
						<div style="font-size: 30px;">
							Fit a least-square plane with the points in $N(x_0,y_0)$, i.e., fit the model,
							$$z_{ij}=\alpha+\beta_1 x_i+\beta_2 y_j + \eta_{ij}, \eta_{ij}\text{ i.i.d. error}$$
							<hr>
							<div style="font-size: 26px;">
								For our example, we obtained: $\hat{z}=2.9+7.2x-7.3y$ & $RSS=15.242$
							</div>
							<div style="text-align: center;">
								<iframe data-src="media/lsplane.html" scrolling="no" height="450px" width="500px" frameborder="0"></iframe>
							</div>
							<!-- By <a href="https://www.google.com">one theorem</a>, $\hat{\beta_1}, \hat{\beta_2}$ contains jump-information.
							<br>
							$\vec{v_{ij}}=(\hat{\beta_1}, \hat{\beta_2})$ denotes the direction of jump. -->
						</div>
					</section>
					<section>
						<h4>
							Proposed Method : Step 2 (Contd.)
						</h4>
						<div style="font-size: 30px;">
							The least square plane is perpendicular to the vector $(\hat{\beta_1}, \hat{\beta_2}, -1)$
							<hr>
							Let's draw the normal vector $(7.2, -7.3, -1)$:
							<div style="text-align: center;">
								<iframe data-src="media/lsplaneiso.html" scrolling="no" height="500px" width="500px" frameborder="0"></iframe>
							</div>
						</div>
					</section>
					<section>
						<h4>
							Proposed Method : Step 2 (Contd.)
						</h4>
						<div style="font-size: 30px;">
							So, $\vec{v_{ij}}=(\hat{\beta_1}, \hat{\beta_2})$ denotes the direction of jump.
							<hr>
							Here is the grid with the vector $\vec{v_{ij}}=(7.2, -7.3)$ on $x-y$ plane:
							<div style="text-align: center;">
								<iframe data-src="media/projected.html" scrolling="no" height="500px" width="500px" frameborder="0"></iframe>
							</div>
						</div>
					</section>
					<section>
						<h4>
							Proposed Method : Step 2 (Contd.)
						</h4>
						<div style="font-size: 30px;">
							The jump location curve can be approximated by a straight line perpendicular to $\vec{v_{ij}}$, i.e., parallel to $(-\hat{\beta_2}, \hat{\beta_1})$.
							So, the partitioning line is of the form, $\hat{\beta_1}x+\hat{\beta_2}y=c$, but $c$ is unknown.
							<hr>
							Here are 3 parallel lines for $c=$<div style="display: inline; background-color: #DDDDDD;"><font color="green">$-2.2,$</font><font color="black">$-3.0,$</font><font color="blue">$-3.2$</font></div>
							<div style="text-align: center;">
								<iframe data-src="media/parallel.html" scrolling="no" height="500px" width="500px" frameborder="0"></iframe>
							</div>
						</div>
					</section>
				</section>
				<section style="text-align: left;">
					<section>
						<h4>
							Proposed Method : Step 3
						</h4>
						<div style="font-size: 30px;">
							Now we want to find the best $c$. But, how do we define &ldquo;best&rdquo; in this context?
							<br>
							<ul>
								<li>
									For each $c$, we get one straight line. Therefore, we have a partition of $N(x_0,y_0)$ with 2 disjoint parts.
								</li>
								<li>
									In each part, we can fit a least-square plane.
								</li>
								<li>
									From these two planes, we can calculate residual sum of squares. Call it $RSS(c)$
								</li>
								<li>
									Optimal $c$ is given by, $c_{opt}=\underset{c\in \mathbb{R}}{\operatorname{arg min}}RSS(c)$
								</li>
							</ul>
						</div>
					</section>
					<section>
						<h4>
							Proposed Method : Step 3 (Contd.)
						</h4>
						<div style="font-size: 30px;">
							Here is the partition for $c=-3.0$
							<br>
							<div style="text-align: center;">
								<ul>
									<li style="color: green;">
										$\hat{\beta_1}x+\hat{\beta_2}y\leq c$
									</li>
									<li style="color: red;">
										$\hat{\beta_1}x+\hat{\beta_2}y> c$
									</li>
								</ul>
							</div>
							<div style="text-align: center;">
								<iframe data-src="media/partition-3.html" scrolling="no" height="500px" width="500px" frameborder="0"></iframe>
							</div>
						</div>
					</section>
					<section>
						<h4>
							Proposed Method : Step 3 (Contd.)
						</h4>
						<div style="font-size: 30px;">
							Two least square planes:
							<br>
							<!-- <div style="text-align: center;">
								<ul>
									<li style="color: green;">
										$\hat{\beta_1}x+\hat{\beta_2}y\leq c$
									</li>
									<li style="color: red;">
										$\hat{\beta_1}x+\hat{\beta_2}y> c$
									</li>
								</ul>
							</div> -->
							<div style="text-align: center;">
								<iframe data-src="media/2planes.html" scrolling="no" height="450px" width="500px" frameborder="0"></iframe>
								<br>
								$RSS(c)=$<font color="green">$0.396$</font>$+$<font color="red">$8.932$</font>$=9.328$
							</div>
						</div>
					</section>
					<section>
						<h4>
							Proposed Method : Step 3 (Contd.)
						</h4>
						<div style="font-size: 30px;">
							Want to find $c_{opt}$.
							<br>
							<div style="text-align: center;">
								<img data-src="media/RSSc.png">
								<br>
								<strong>$c_{opt}=-2.63$</strong>
							</div>
						</div>
					</section>
					<section>
						<h4>
							Proposed Method : Step 3 (Contd.)
						</h4>
						<div style="font-size: 30px;">
							Optimal partitioning obtained from $\hat{\beta_1}x+\hat{\beta_2}y=c_{opt}$
							<br>
							<div style="text-align: center;">
								<iframe data-src="media/optimalplanes.html" scrolling="no" height="450px" width="500px" frameborder="0"></iframe>
								<br>
								<strong>$RSS(c_{opt})=5.614$</strong>
							</div>
						</div>
					</section>
				</section>
				<section style="text-align: left;">
					<section>
						<h4>
							Proposed Method : Step 4
						</h4>
						<div style="font-size: 30px;">
							We have obtained a partition. But <strong>is there really a partition?</strong>
							<br>
							<ul>
								<li class="fragment fade-down" data-fragment-index="1">
									While we fitted a single plane, we obtained one value of $RSS$. Call it $RSS_0$
								</li>
								<li class="fragment fade-up" data-fragment-index="1">
									For the partitioned fit, we obtained $RSS(c_{opt})$, smaller than $RSS_0$.
								</li>
								<li class="fragment fade-down" data-fragment-index="2">
									If there really exists a jump in the neighbourhood, then we expect that $RSS_0$ would be significantly higher than $RSS(c_{opt})$. Otherwise, they would be close to each other.
								</li>
								<li class="fragment fade-up" data-fragment-index="2">
									So we can do a hypothesis testing to determine whether we should <strong>trust</strong> the obtained partition.
								</li>
							</ul>
						</div>
					</section>
					<section>
						<h4>
							Proposed Method : Step 4 (Contd.)
						</h4>
						<div style="font-size: 30px;">
							<strong>Hypothesis testing:</strong>
							$$H_0:\text{Jump location curve passes through the neighbourhood}$$
							$$H_A:H_0\text{ is false}$$
							<div class="fragment">
								In other words, we have the model:
								$$z_{ij} = \begin{cases} 
								\left(p_1+q_1x_i+r_1y_j+\eta_{ij} \right), & \text{if }(x_i,y_j)\in \text{Cluster-1} \\
								\left(p_2+q_2x_i+r_2y_j+\eta_{ij} \right), & \text{if }(x_i,y_j)\in \text{Cluster-2}
								\end{cases}
								$$
							</div>
							<div class="fragment">
								and, we want to test,
								$$H_0:p_1=p_2,q_1=q_2,r_1=r_2$$
								$$H_A:H_0\text{ is false}$$
							</div>
						</div>
					</section>
					<section>
						<h4>
							Proposed Method : Step 4 (Contd.)
						</h4>
						<div style="font-size: 30px;">
							<strong>Hypothesis testing:</strong>
							We had assumed that noises follow $N(0,\sigma^2)$
							We can do $F\text{-test}$:
							$$F=\frac{\left(RSS_0-RSS(c_{opt})\right)/3}{RSS(c_{opt})/(m-6)},m=\#N(x_0,y_0)$$
							$$\text{Under }H_0, F\sim F_{3,m-6}$$
							Based on level of significance $\alpha$, we can make a decision.
							<div class="fragment fade-up">
								<hr>
								We had, $RSS_0=15.242$, $RSS(c_{opt})=5.614$.
								<br>
								$m=13\times 13=169$. Set $\alpha=0.001$
								<br>
								Hence, $F=93.179$. Therefore, $p\text{-value}=3.63\times 10^{-35}$
								<br>
								<strong>Conclusion:</strong> There is a jump location curve passing through the neighbourhood. So we shall work with the obtained partition.
							</div>
					</section>
				</section>
				<section>
					<section data-auto-animate data-auto-animate-easing="cubic-bezier(0.770, 0.000, 0.175, 1.000)"><h3 data-id="heading">V Slide 1</h1><p data-id="equation">$$y=x^2$$</p></section>
					<section data-auto-animate data-auto-animaye-easing="cubic-bezier(0.770, 0.000, 0.175, 1.000)"><h3 data-id="heading">V Slide 2</h1><p>$$(a+b)^2=a^2+2ab+b^2$$</p><p data-id="equation">$$y=x^3$$</p></section>
				</section>
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/zoom/zoom.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>
		<script src="plugin/chalkboard/plugin.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				transition: 'convex',
				// math: {
				// // mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js' // online
				// mathjax: 'node_modules/mathjax/es5/tex-chtml-full.js' //offline-local
				// },
				// chalkboard: {
				// 	// src: "chalkboard/chalkboard.json",
				// 	toggleChalkboardButton: { left: "80px" },
				// 	toggleNotesButton: { left: "130px" },
				// },
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath, RevealChalkboard, RevealZoom],
			});
			// Reveal.addEventListener("blackTheme", function(){setTimeout(function(){document.getElementById('theme').setAttribute('href','dist/theme/black.css'); return false;}, 1000);});
			// Reveal.addEventListener("moonTheme", function(){setTimeout(function(){document.getElementById('theme').setAttribute('href','dist/theme/moon.css'); return false;}, 1000);});
			// Reveal.addEventListener("moonTheme", function(){document.getElementById('theme').setAttribute('href','dist/theme/moon.css'); return false;});
		</script>
	</body>
</html>
